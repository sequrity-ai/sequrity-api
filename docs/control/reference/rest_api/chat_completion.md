# Chat Completion API

The Sequrity Control Chat Completion API is compatible with the [OpenAI Chat Completions API](https://platform.openai.com/docs/api-reference/chat). This allows you to use Sequrity's security features while maintaining compatibility with existing OpenAI-based applications.

For the Anthropic Messages format, see the [Messages API](./messages.md) reference.

## Endpoints

| Endpoint | Provider |
|----------|----------|
| `POST /control/{endpoint_type}/v1/chat/completions` | Default |
| `POST /control/{endpoint_type}/openai/v1/chat/completions` | OpenAI |
| `POST /control/{endpoint_type}/openrouter/v1/chat/completions` | OpenRouter |
| `POST /control/{endpoint_type}/sequrity_azure/v1/chat/completions` | Sequrity Azure |

Where `{endpoint_type}` is `chat`, `code`, `agent`, or `lang-graph`. See [URL Pattern](./index.md#url-pattern) and [Service Providers](../../../general/rest_api/service_provider.md).

## Request Body

| Field | Type | Required | Description |
|-------|------|----------|-------------|
| `messages` | `array[Message]` | Yes | A list of messages comprising the conversation so far. See [Message Types](#message-types). |
| `model` | `string` | Yes | Model ID, e.g. `openai/gpt-5-mini`. For Dual-LLM, specify two models separated by a comma (`pllm,qllm`). |
| `temperature` | `float` | No | Sampling temperature (0–2). Higher values produce more random output. |
| `top_p` | `float` | No | Nucleus sampling threshold. Use `0.1` for top 10% probability mass. |
| `tools` | `array[Tool]` | No | Tools the model may call. See [Tools](#tools). |
| `stream` | `boolean` | No | If `true`, partial deltas are sent as server-sent events. |
| `seed` | `integer` | No | Seed for deterministic sampling (best-effort). |
| `reasoning_effort` | `string` | No | Reasoning effort for reasoning models: `"minimal"`, `"low"`, `"medium"`, `"high"`. |
| `response_format` | `object` | No | Output format constraint. See [Response Format](#response-format). |

### Message Types

Messages are distinguished by the `role` field.

#### System Message

| Field | Type | Required | Description |
|-------|------|----------|-------------|
| `role` | `"system"` | Yes | |
| `content` | `string \| array[ContentPartText]` | Yes | The system prompt. |
| `name` | `string` | No | Optional participant name. |

#### Developer Message

| Field | Type | Required | Description |
|-------|------|----------|-------------|
| `role` | `"developer"` | Yes | |
| `content` | `string \| array[ContentPartText]` | Yes | The developer message. |
| `name` | `string` | No | Optional participant name. |

#### User Message

| Field | Type | Required | Description |
|-------|------|----------|-------------|
| `role` | `"user"` | Yes | |
| `content` | `string \| array[ContentPart]` | Yes | Supports text, images, audio, and files. See [Content Parts](#content-parts). |
| `name` | `string` | No | Optional participant name. |

#### Assistant Message

| Field | Type | Required | Description |
|-------|------|----------|-------------|
| `role` | `"assistant"` | Yes | |
| `content` | `string \| array[ContentPartText \| ContentPartRefusal] \| null` | No | Required unless `tool_calls` is specified. |
| `name` | `string` | No | Optional participant name. |
| `refusal` | `string` | No | Refusal message by the assistant. |
| `audio` | `object` | No | Reference to a previous audio response. |
| `tool_calls` | `array[ToolCall]` | No | Tool calls generated by the model. |
| `function_call` | `object` | No | **Deprecated.** Use `tool_calls`. |

#### Tool Message

| Field | Type | Required | Description |
|-------|------|----------|-------------|
| `role` | `"tool"` | Yes | |
| `content` | `string \| array[ContentPartText]` | Yes | The tool result. |
| `tool_call_id` | `string` | Yes | ID of the tool call this responds to. |

#### Function Message (deprecated)

| Field | Type | Required | Description |
|-------|------|----------|-------------|
| `role` | `"function"` | Yes | |
| `content` | `string \| null` | Yes | The function result. |
| `name` | `string` | Yes | The function name. |

### Content Parts

User messages support multimodal content:

| Type | Key Fields | Description |
|------|------------|-------------|
| `text` | `type`, `text` | Plain text. |
| `image_url` | `type`, `image_url.url`, `image_url.detail` | Image via URL or base64. Detail: `"auto"`, `"low"`, `"high"`. |
| `input_audio` | `type`, `input_audio.data`, `input_audio.format` | Audio as base64. Format: `"wav"`, `"mp3"`. |
| `file` | `type`, `file.file_data`, `file.file_id`, `file.filename` | File via base64 or file ID. |

### Tools

| Field | Type | Required | Description |
|-------|------|----------|-------------|
| `type` | `"function"` | Yes | Currently only `"function"` is supported. |
| `function.name` | `string` | Yes | Function name (a-z, A-Z, 0-9, underscores, dashes; max 64 chars). |
| `function.description` | `string` | No | What the function does. |
| `function.parameters` | `object` | No | JSON Schema describing the function parameters. |
| `function.strict` | `boolean` | No | Enable strict schema adherence. |

### Response Format

| Type | Description |
|------|-------------|
| `text` | Default text response. |
| `json_object` | JSON mode — model outputs valid JSON. |
| `json_schema` | Structured Outputs with a JSON Schema. Fields: `name`, `description`, `schema`, `strict`. |

## Response Body

| Field | Type | Description |
|-------|------|-------------|
| `id` | `string` | Unique identifier for the chat completion. |
| `object` | `"chat.completion"` | Always `"chat.completion"`. |
| `created` | `integer` | Unix timestamp (seconds) when created. |
| `model` | `string` | The model used. |
| `choices` | `array[Choice]` | Completion choices. |
| `usage` | `CompletionUsage` | Token usage statistics. |
| `session_id` | `string \| null` | Sequrity session ID (also available via `X-Session-ID` response header). |

### Choice

| Field | Type | Description |
|-------|------|-------------|
| `index` | `integer` | Index of this choice. |
| `message` | `ResponseMessage` | The generated message. |
| `finish_reason` | `string` | Why generation stopped: `"stop"`, `"length"`, `"tool_calls"`, `"content_filter"`, `"error"`. |
| `logprobs` | `object \| null` | Log probability information, if requested. |

### Response Message

| Field | Type | Description |
|-------|------|-------------|
| `role` | `"assistant"` | Always `"assistant"`. |
| `content` | `string \| null` | The message content. |
| `refusal` | `string \| null` | Refusal message, if applicable. |
| `annotations` | `array[Annotation] \| null` | URL citations (e.g. from web search). |
| `audio` | `object \| null` | Audio response data. |
| `tool_calls` | `array[ToolCall] \| null` | Tool calls generated by the model. |

### ToolCall

| Field | Type | Description |
|-------|------|-------------|
| `id` | `string` | The tool call ID. |
| `type` | `"function"` | Always `"function"`. |
| `function.name` | `string` | Name of the called function. |
| `function.arguments` | `string` | JSON-encoded arguments. |

### CompletionUsage

| Field | Type | Description |
|-------|------|-------------|
| `prompt_tokens` | `integer` | Tokens in the prompt. |
| `completion_tokens` | `integer` | Tokens in the completion. |
| `total_tokens` | `integer` | Total tokens used. |

## Headers

See [Custom Headers](./index.md#custom-headers) for the full list. Summary:

| Header | Direction | Description |
|--------|-----------|-------------|
| `Authorization` | Request | `Bearer <sequrity-api-key>` |
| `X-Api-Key` | Request | LLM provider API key (BYOK). |
| `X-Features` | Request | [Security features](./headers/security_features.md) (agent arch, classifiers, blockers). |
| `X-Policy` | Request | [Security policy](./headers/security_policy.md) (SQRT rules). |
| `X-Config` | Request | [Fine-grained config](./headers/security_config.md) (FSM, prompts, response format). |
| `X-Session-ID` | Request | Explicit session ID for multi-turn conversations. |
| `X-Session-ID` | Response | Session ID assigned by the server. |

## Examples

### Request

=== "Single LLM"

    ```bash
    --8<-- "examples/control/getting_started/first_message/rest_api.sh:setup_env_vars"

    --8<-- "examples/control/getting_started/first_message/rest_api.sh:single_llm"
    ```

=== "Dual LLM"

    ```bash
    --8<-- "examples/control/getting_started/first_message/rest_api.sh:setup_env_vars"

    --8<-- "examples/control/getting_started/first_message/rest_api.sh:dual_llm"
    ```

### Response

=== "Single LLM"

    ```json
    {
        "id": "gen-1769519573-03eFDboLr45TxWIgz76t",
        "choices": [
            {
                "finish_reason": "stop",
                "index": 0,
                "message": {
                    "content": "97\n\nExplanation: 99, 98, and 100 are composite ...",
                    "role": "assistant"
                }
            }
        ],
        "created": 1769519573,
        "model": "openai/gpt-5-mini",
        "object": "chat.completion",
        "usage": {
            "completion_tokens": 186,
            "prompt_tokens": 16,
            "total_tokens": 202
        }
    }
    ```

=== "Dual LLM"

    ```json
    {
        "id": "e71f5e2f-fb81-11f0-a50b-b80bf871da67",
        "choices": [
            {
                "finish_reason": "stop",
                "index": 0,
                "message": {
                    "content": "{\"status\": \"success\", \"final_return_value\": {\"value\": 97, \"meta\": {\"tags\": [], \"consumers\": [\"*\"], \"producers\": []}}}",
                    "role": "assistant"
                }
            }
        ],
        "created": 1769519589,
        "model": "openai/gpt-5-mini,openai/gpt-5-mini",
        "object": "chat.completion",
        "usage": {
            "completion_tokens": 354,
            "prompt_tokens": 2885,
            "total_tokens": 3239
        }
    }
    ```
